{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Workshop-Visualizacion.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otoperalias/Coyuntura/blob/main/clases/Tema2_VI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s_f1b3Ksbt0"
      },
      "source": [
        "## Procesamiento de datos para su análisis y visualización\n",
        "\n",
        "En este notebook vamos a importar de [EUROSTAT](https://ec.europa.eu/eurostat/web/main/data/database) datos de PIB y paro para los países de la UE y a procesarlos para poder, posteriormente, visualizarlos y analizarlos.\n",
        "\n",
        "La gran ventaja de importar y procesar los datos en Python es que, al automatizar el proceso, resulta mucho más rápido volver a realizar la misma tarea. Además, tener el código escrito nos ayuda a identificar y a corregir errores, los cuales son muy difíciles de detectar si realizamos la manipulación de datos en Excel.\n",
        "\n",
        "*Daniel Oto-Peralías*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0_yPfqQtRT3"
      },
      "source": [
        "### Importamos las librerías que necesitamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tYx0AUjsbt4"
      },
      "source": [
        "# IMPORTAMOS LIBRERIAS\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_row', 100)\n",
        "pd.set_option('display.max_columns', 30)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PIB en volumen"
      ],
      "metadata": {
        "id": "gwflwfsSxmgT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqk5h9TMsbt5"
      },
      "source": [
        "# PIB en volúmen (Gross domestic product, volumes (teina011))\n",
        "link_pib=\"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/teina011?format=TSV&compressed=true\"\n",
        "pib = pd.read_csv(link_pib, compression='gzip', header=0, sep='\\t')\n",
        "pib # En el excel de EUROSTAT podemos comprobar que son tablas equivalentes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a hacer el siguiente procesamiento a los datos:\n",
        "1. Dividimos la columna ```freq,na_item,unit,geo\\TIME_PERIOD``` en cuatro columnas.\n",
        "2. Seleccionamos solo la unidad \"PCH_Q1_SCA\" que significa \"Percentage change, Annual variation rate, Seasonally and Calendar Adjusted.\n",
        "3. Borramos los valores \"p\" y los \":\".\n",
        "4. Transponemos la tabla.\n",
        "5. Usamos los nombres de países como nombre de las columnas.\n",
        "6. Convertimos las columnas en formato numérico.\n",
        "7. Establecemos el index de la tabla como fecha.\n",
        "8. Guardamos los datos en un fichero csv.\n"
      ],
      "metadata": {
        "id": "qB11mw2axzjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Dividimos la columna en tres.\n",
        "# Hay que separar por la coma\n",
        "pib[['freq','na_item','unit','geo']]=pib[r'freq,na_item,unit,geo\\TIME_PERIOD'].str.split(\",\", expand=True)\n",
        "pib.drop(columns=r'freq,na_item,unit,geo\\TIME_PERIOD',inplace=True)\n",
        "pib"
      ],
      "metadata": {
        "id": "oFEZFssM70h-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Seleccionamos solo la variable PCH_Q4_SCA\n",
        "pib=pib.loc[pib['unit']==\"PCH_Q4_SCA\"]\n",
        "pib"
      ],
      "metadata": {
        "id": "CifE_08CA9uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Borramos los valores p y los :\n",
        "for col in pib.columns:\n",
        "  pib[col]=pib[col].replace(\"p\",\"\",regex=True) # Dejamos espacio adelante porque dicho espacio existe en los datos.\n",
        "  pib[col]=pib[col].replace(\":\",\"\",regex=True)\n",
        "  pib[col]=pib[col].replace(\" \",\"\",regex=True) # por si hay algún espacio\n",
        "pib"
      ],
      "metadata": {
        "id": "D23bmhZk9RXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Transponemos la tabla\n",
        "pib=pib.transpose()\n",
        "pib"
      ],
      "metadata": {
        "id": "5-KBqv8tBTeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Usamos la fila de nombres de países como nombres de las columnas\n",
        "nombre_col = pib.iloc[-1] # Los nombres de países están en la última fila\n",
        "pib = pib.iloc[:-4] # aplicamos un filtrado para quitar las 4 últimas filas\n",
        "pib.columns = nombre_col # Establecemos el nuevo nombre de las columnas\n",
        "pib"
      ],
      "metadata": {
        "id": "65xqIhHAKBde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Convertimos las columnas en formato numérico.\n",
        "for col in pib.columns:\n",
        "  pib[col]=pd.to_numeric(pib[col], errors='coerce')\n",
        "pib"
      ],
      "metadata": {
        "id": "MCPeOccO-si8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Establecemos el index de la tabla como fecha\n",
        "pib.index=pib.index.str.replace(\" \",\"\",regex=True)\n",
        "pib.index=pd.to_datetime(pib.index)\n",
        "pib"
      ],
      "metadata": {
        "id": "iD_mnWWHNfNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Guardamos los datos en un fichero csv.\n",
        "pib.to_csv(\"pib_volumen_EUROSTAT.csv\")"
      ],
      "metadata": {
        "id": "QzRTxqhSTVh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nótese que el archivo \"pib_volumen_EUROSTAT.csv\" se ha guardado en la carpeta de archivos de Google Colab. Por tanto, tenemos que descargarla en nuestro ordenador."
      ],
      "metadata": {
        "id": "qlFPbUe_Thp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tasa de desempleo\n",
        "\n",
        "Repetimos los mismos pasos que anteriormente para el PIB, pero adaptando el código a las particularidades de la tabla de datos del paro."
      ],
      "metadata": {
        "id": "A4r6jQmFxgDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tasa de desempleo (Total unemployment rate (tps00203))\n",
        "link_des=\"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/une_rt_q?format=TSV&compressed=true\"\n",
        "tp = pd.read_csv(link_des, compression='gzip', header=0, sep='\\t')\n",
        "tp"
      ],
      "metadata": {
        "id": "HYzEFe9RwLms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Dividimos la columna en seis (hay que separar por la coma)\n",
        "columna=r'freq,s_adj,age,unit,sex,geo\\TIME_PERIOD'\n",
        "tp[['freq','s_adj','age','unit','sex','geo']]=tp[columna].str.split(\",\", expand=True)\n",
        "tp.drop(columns=columna,inplace=True)\n",
        "tp"
      ],
      "metadata": {
        "id": "cxHRJyXQUVcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploramos un poco los datos\n",
        "tp.unit.value_counts()\n"
      ],
      "metadata": {
        "id": "-Z24p2ZbXSpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Seleccionamos SA, Y15-74, PC_ACT, T\n",
        "tp=tp.loc[(tp['s_adj']==\"SA\") &\n",
        "          (tp['age']==\"Y15-74\") &\n",
        "          (tp['unit']==\"PC_ACT\") &\n",
        "          (tp['sex']==\"T\")]\n",
        "tp"
      ],
      "metadata": {
        "id": "rZMrY7xAVUjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Borramos los valores p y los :\n",
        "for col in tp.columns:\n",
        "  for c in [\"p\",\"d\",\"u\",\"b\",\":\",\" \"]:\n",
        "    tp[col]=tp[col].replace(c,\"\",regex=True)\n",
        "tp"
      ],
      "metadata": {
        "id": "mIOb9LdS92Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Transponemos la tabla\n",
        "tp=tp.transpose()\n",
        "tp"
      ],
      "metadata": {
        "id": "RslZJHO5-AbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Usamos la fila de nombres de países como nombres de las columnas\n",
        "nombre_col = tp.iloc[-1] # Los nombres de países están en la última fila\n",
        "tp = tp.iloc[:-6] # aplicamos un filtrado para quitar las seis últimas filas\n",
        "tp.columns = nombre_col # Establecemos el nuevo nombre de las columnas\n",
        "\n",
        "# 6. Convertimos las columnas en formato numérico.\n",
        "for col in tp.columns:\n",
        "  tp[col]=pd.to_numeric(tp[col], errors='coerce')\n",
        "\n",
        "#7. Establecemos el index de la tabla como fecha\n",
        "tp.index=tp.index.str.replace(\" \",\"\",regex=True)\n",
        "tp.index=pd.to_datetime(tp.index)\n",
        "tp.sort_index(inplace=True)\n",
        "\n",
        "#8. Guardamos los datos en un fichero csv.\n",
        "tp.to_csv(\"Tasa_paro_EUROSTAT.csv\")\n",
        "tp"
      ],
      "metadata": {
        "id": "XjHW8yYHYv9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}